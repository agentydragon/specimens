"""CLI command to classify command patterns as no-ops using LLM classifier."""

from __future__ import annotations

import asyncio
import json
import logging
from pathlib import Path
from typing import Annotated

import typer
from rich.console import Console

from openai_utils.client_factory import build_client
from props.cli import common_options as opt
from props.core.noop_classifier.classifier import classify_patterns_parallel

logger = logging.getLogger(__name__)


def cmd_classify_noops(
    input_file: Annotated[Path, typer.Option("--input", help="Input file with command patterns")] = Path(
        "docker_exec_patterns.json"
    ),
    output_file: Annotated[Path, typer.Option("--output", help="Output file for classifications")] = Path(
        "noop_classifications.json"
    ),
    model: Annotated[str, typer.Option(help="Model id")] = "gpt-5.1-codex-mini",
    batch_size: Annotated[int, typer.Option("--batch-size", help="Number of patterns per batch")] = 10,
    max_parallel: int = opt.OPT_MAX_PARALLEL,
    verbose: bool = opt.OPT_VERBOSE,
) -> None:
    """Classify command patterns as no-ops using LLM.

    Reads patterns from input JSON (generated by analyze-exec),
    classifies each as no-op or not, and writes results to output JSON.

    Uses work-stealing parallelism: N workers grab batches from a shared queue
    as they complete previous batches, providing automatic load balancing.

    Args:
        input_file: Path to JSON with pattern data from analyze-exec
        output_file: Path to write classification results
        model: OpenAI model to use
        batch_size: Patterns per batch
        max_parallel: Number of parallel workers
        verbose: Enable verbose output
    """
    console = Console()

    # Load patterns from JSON
    if not input_file.exists():
        console.print(f"[red]Input file not found: {input_file}[/red]")
        raise typer.Exit(1)

    with input_file.open() as f:
        patterns_data = json.load(f)

    # Extract just the prefixes (cmd arrays)
    patterns = [item["prefix"] for item in patterns_data]

    if not patterns:
        console.print("[yellow]No patterns to classify[/yellow]")
        return

    console.print(f"[bold]Classifying {len(patterns)} patterns[/bold]")
    console.print(f"Model: {model}")
    console.print(f"Batch size: {batch_size}")
    console.print(f"Workers: {max_parallel}")

    # Build OpenAI client
    client = build_client(model)

    # Run classification
    async def _run():
        return await classify_patterns_parallel(patterns, client, max_parallel, batch_size, verbose=verbose)

    classifications = asyncio.run(_run())

    # Write results to JSON
    results = [c.model_dump(mode="json") for c in classifications]
    with output_file.open("w") as f:
        json.dump(results, f, indent=2)

    console.print(f"\n[green]Wrote {len(classifications)} classifications to {output_file}[/green]")

    # Show summary stats
    num_noops = sum(1 for c in classifications if c.is_noop)
    num_not_noops = len(classifications) - num_noops

    console.print("\n[bold]Summary:[/bold]")
    console.print(f"  No-ops: {num_noops} ({num_noops / len(classifications) * 100:.1f}%)")
    console.print(f"  Not no-ops: {num_not_noops} ({num_not_noops / len(classifications) * 100:.1f}%)")
